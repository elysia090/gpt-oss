Sera Transfer Kit (STK) — Deterministic GPU-free Projection Specification (Tightened)
Plain ASCII, English only. No dummy behavior. Implementation-grade.

0. Purpose

STK converts an open-weight Transformer checkpoint into a Sera-compatible constant-time runtime package using only CPUs.

* No GPUs, no training, no fine-tuning.
* O(N_params) preprocessing; Sera runtime remains O(1) per event.
* Exactly reproducible: same inputs -> bitwise-identical outputs.
* All semantics are encoded in:

  * a manifest (sera_manifest.bin)
  * a fixed set of binary arrays (arrays/*.bin)
* Sera activates a model by a single pointer swap to a validated generation.

All nondeterminism sources (threading, BLAS behavior, random sampling) are eliminated or fixed.

1. Deterministic environment model

1.1 Determinism

Implementation MUST enforce:

* Fixed PRNG: splitmix64 (section 6).
* No time-based or OS-random seeds.
* Stable reduction orders:

  * layer index ascending
  * tensor role fixed order
  * row-major within each tensor
* Linear algebra:

  * Householder QR only.
  * R diagonal forced positive.
  * No vendor-randomized pivoting.
* No use of "fast but non-deterministic" BLAS modes.

1.2 Threading

* Thread count T fixed by CLI.
* Threads pinned to cores [0..T-1].
* No work stealing, no dynamic creation inside core kernels.
* Collective operations use fixed tree or serial reductions.

1.3 Memory discipline

* Model weights mapped read-only via mmap or equivalent.

* Streaming by layer:

  * At most one (or a bounded small number of) full-layer tensors in RAM.

* Peak memory:

  peak_bytes <= max_layer_bytes + 512 MiB

* No unbounded containers, no amortized growth in inner loops.

* All array files are write-once:

  * payload written
  * header filled
  * checksums computed
  * then file is immutable.

2. Inputs

2.1 Required

* Weights:

  * `input/model.safetensors` or equivalent
  * or `input/pytorch_model.bin`
* Config:

  * `input/config.json`

    * Includes or allows inference of:

      * num_hidden_layers
      * hidden_size (d_model_candidate)
      * num_attention_heads, num_key_value_heads, head_dim (if any)
      * vocab_size
      * MoE metadata if any (num_experts, experts_per_token)
      * RoPE/ALiBi/other positional parameters, if any

2.2 Optional

* Tokenizer:

  * `input/tokenizer.model`
  * or `merges.txt` + `vocab.json`
* If unsupported:

  * STK emits a tokenizer wrapper entry (no FST), still deterministic.

2.3 Authoritative shapes

If config.json and actual tensor shapes disagree:

* Actual tensor shapes are authoritative.
* Manifest records both:

  * `config_declared_*`
  * `effective_*`
* All downstream constructions use effective shapes only.

3. Outputs

3.1 Files

* `output/sera_manifest.bin`
* `output/arrays/*.bin`

No other files are read by Sera runtime.

3.2 Common array header (64 bytes, LE)

All `*.bin` arrays share this exact header:

* u32 magic        = 0x53455241              // "SERA"
* u16 dtype        // 1=f64,2=f32,3=i32,4=i16,5=i8,6=u8,7=q8_8,8=q4_12,9=bf16
* u16 rank
* u64 dims[5]      // product(dims) * sizeof(dtype) == byte_len; unused slots = 1
* u64 byte_len     // payload bytes, excluding header
* u64 crc32c       // CRC32C of payload
* u64 sha256_low64 // low 64 bits of SHA-256(payload)
* u32 flags

  * bit0: row_major (if set, row-major C-order)
  * bit1: aligned_64B (payload start is 64-byte aligned)
  * bit2: ftz_on (runtime may assume flush-to-zero)
* u32 reserved     // must be 0

Payload:

* Starts immediately after header.
* 64-byte aligned.
* Never modified after header finalization.

3.3 Core arrays (by role)

Tokenizer:

* tokenizer_fst.bin         // optional; omitted for unsupported tokenizer types
* T_1.bin .. T_Ltok.bin     // per-length lookup tables (if FST/table tokenizer used)

PRF and whitening:

* prf_W.bin                 // [r, d_model_eff], f32 or f64
* R_init.bin                // [r, d_v], f32
* s_init.bin                // [r], f32
* whitening_mu.bin          // [r], f32
* whitening_sig2.bin        // [r], f32

Overlays:

* overlays_H.bin            // [r, r_v], f32
* overlays_U.bin            // [d_v, r_v], f32
* overlays_DeltaW.bin       // [r_v, r_v], f32

Linear:

* linear_mphf.bin           // MPHF metadata
* linear_keys.bin           // [C], u64 (audit only)
* linear_weights.bin        // [C], f32
* cuckoo_delta.bin          // encoded (key, val) residuals

Memory:

* memory_coeff.bin          // AR/ARMA/SOS coeffs, f64
* delaybuf_init.bin         // initial DF-II state

Bridge:

* bridge_hubs.bin           // [N_hub_contexts, H_words], u64
* bridge_qDin.bin           // quantized inbound projections
* bridge_qDout.bin          // quantized outbound projections
* peer_scores.bin           // [N_peers], q8_8

Omission:

* If any optional array is missing:

  * The corresponding feature is OFF.
  * Runtime behavior must be well-defined neutral (e.g. no overlays, no O(0) guards).

4. Manifest (sera_manifest.bin)

4.1 Header

Binary struct (LE):

* u32 magic          = 0x5345524D            // "SERM"
* u8  endian         = 1                     // 1 = little-endian
* u8  abi_flags      // bit0=FMA, bit1=FTZ, others reserved
* u16 reserved0      // zero
* u64 seed_digest_lo // low 64 bits of SHA-256 over seed schedule description
* u64 seed_digest_hi
* u64 schema_sha256_lo
* u64 schema_sha256_hi

`schema_sha256_*` is the hash of this manifest schema and field ordering.

4.2 Sections (compact encoding allowed; here logical view)

Each subsection has fixed field order; all numeric fields bounded.

Tokenizer:

* u16 L_tok
* u16 S_norm
* u16 L_norm
* u16 reserved
* u32 P_gen_count
* u64 sp_cert_digest_lo, sp_cert_digest_hi
* u8  unicode_policy   // enum

PRF:

* u32 r
* f32 tau
* f32 whitening_eps
* f32 clip_c

Denominator:

* f32 beta_floor
* u64 lambda_star_digest_lo, lambda_star_digest_hi

Linear:

* u64 C                 // MPHF capacity
* u32 d                 // input features logical
* u32 b                 // bucket size
* u32 S                 // stash size
* u32 L_cuckoo
* u32 Q                 // ring capacity
* f32 tau_low
* f32 tau_high

Memory:

* u8  mode              // 0=NONE,1=SOS,2=ARMA
* u8  p
* u8  q
* u8  L
* u32 T_phi
* u32 K
* f32 pole_radius_min

Overlays:

* u32 P
* u32 k_max
* u32 r_v

CCR cert (if used):

* f32 gamma_CCR_target
* f32 m_target
* u8  norm_def
* u8  reserved[3]

Bridge:

* u8  K
* u8  W
* u16 reserved
* u32 proj_rows
* u32 proj_cols
* u64 proj_digest_lo, proj_digest_hi
* f32 beta_min
* f32 beta_max
* f32 guard_margin_policy
* f32 guard_eps_row_policy
* f32 load_max
* f32 stash_max
* f32 kick_max

Search (if tree/heuristic used):

* f32 A_max
* f32 A_cap
* f32 H_sel
* f32 H_roll
* f32 c_puct
* f32 epsilon
* f32 vloss

Capacity:

* f32 lambda_hat
* f32 T_rb_ms
* f32 slack
* f32 margin

Salts:

* u64 mphf_salt_digest_lo, mphf_salt_digest_hi
* u64 key_salt_digest_lo, key_salt_digest_hi

Hashes:

* u64 prev_hash_lo, prev_hash_hi
* u64 curr_hash_lo, curr_hash_hi

Missing sections or zero values are interpreted as "feature disabled / default" explicitly by Sera ABI.

5. Tensor role mapping

5.1 Roles

Each parameter is mapped to:

* EMB, Q, K, V, O
* FFN_W1, FFN_W2, FFN_B1, FFN_B2
* LN_G, LN_B
* ROUTER_GATE
* ROPE_META (RoPE/positional parameters)

5.2 Mapping algorithm

Inputs:

* Ordered list of (pattern, role) from config.

Algorithm:

* For each tensor name:

  * Traverse list in index order.
  * First pattern that matches fully (regex full or anchored) sets its role.
  * If multiple patterns at same index would match, use lexicographically smallest pattern string (explicit tie-break).
* Unmatched tensors are ignored by STK.
* MoE:

  * Expert tensors discovered via patterns including expert index groups.
  * Experts sorted by:

    1. layer index
    2. expert index
    3. tensor name lexical

No implicit guessing is allowed beyond these rules.

6. PRNG and basic numeric primitives

6.1 splitmix64

State x is u64.

* x += 0x9E3779B97F4A7C15
* z  = (x ^ (x >> 30)) * 0xBF58476D1CE4E5B9
* z  = (z ^ (z >> 27)) * 0x94D049BB133111EB
* z  = z ^ (z >> 31)
* return z

6.2 Uniform double

From u64 v:

* u = (v >> 11) * 2^-53
* Clamp u into [2^-52, 1 - 2^-52].

6.3 Gaussian

Use Box-Muller:

* Given u1,u2 in (0,1), deterministic libm:

  r     = sqrt(-2 * log(u1))
  theta = 2 * pi * u2
  z0    = r * cos(theta)
  z1    = r * sin(theta)

No approximations; same libm across runs and builds.

6.4 Module seeds

Global:

* base_seed: 256-bit user-visible or derived from file hashes.
* Each module uses:

  seed = H(module_id || layer_id || index || base_seed)

via splitmix64 chaining, encoded and documented in manifest (seed_digest).

7. Tokenizer construction

7.1 Supported mode: BPE-like

If merges/vocab represent a byte-level or deterministic BPE:

* Extract tokens as byte sequences.
* Restrict to piece length <= L_tok.
* Reject any epsilon-derivable code using Sardinas-Patterson.

7.2 Sardinas-Patterson

* Run exact algorithm on token set.
* If epsilon is found -> tokenizer is ambiguous:

  * STK may:

    * abort conversion, or
    * mark tokenizer unsupported (no FST), require fallback mode.
* Store `sp_cert_digest = sha256(minimal_witness_set)`.

7.3 Rolling hash

For each token (byte string b[0..k-1]):

* h = 0
* for i in 0..k-1:
  h = h * 257 + b[i]          // mod 2^64 via natural overflow

Store h; used as key in MPHF.

7.4 MPHF per length

For all tokens of length n:

* Let K = count.
* Set M = ceil(1.23 * K).
* Partition by:

  bucket_id = mix64(h) mod M

For each bucket:

* For seed s in [0..65535]:

  * Try assign each key in bucket to one or two candidate positions without collision.
  * If success: record s; break.
* If any bucket fails:

  * Trigger 18.1 (increase M; rebuild only tokenizer MPHF).

Lookup:

* Uses recorded seed and 1-2 indexed slots plus exact token comparison.
* Bound: <= 2 probes per length.

7.5 Encoding

* Greedy longest-match, forward-only.
* Max L_tok attempts per offset.
* No backtracking beyond this.
* Residual bytes at end become fallback tokens.
* Deterministic for any byte string.

8. PRF basis and whitening (attention surrogate)

8.1 Diagonal from K

Effective d_model determined from Q/K shapes.

For each column j:

* Aggregate over heads and rows:

  D_diag[j] = max( mean( W_K^2 over all relevant entries ), eps_wk )

eps_wk = 1e-8.

8.2 prf_W

Given r:

For each i in [0..r):

* For each j in [0..d_model):

  * g_ij from Gaussian sampler.
  * w_ij = g_ij * sqrt(D_diag[j])

* Normalize:

  prf_W[i,j] = w_ij / sqrt(r)

Store as f32 or f64.

8.3 Whitening stats

* whitening_mu[k]   = 0
* whitening_sig2[k] = 1 (or deterministic low-variance adjustment derived from prf_W and D_diag)

8.4 Denominator floor

Compute expected_den on synthetic queries (fixed-seed), then:

* beta_floor = max(1e-3, 5e-4 * expected_den)

Store in manifest.

9. Overlays from W_O

9.1 H

* Construct r x r_v matrix from splitmix64.
* Run Householder QR deterministically.
* Take first r_v columns as overlays_H.
* Ensure orthonormal to tolerance 1e-6.

9.2 U

Given W_O in R^{d_v x d_model}:

* Build Omega in R^{d_v x r_v} via splitmix64 Gaussian.
* Y = W_O^T * Omega
* U_full = Q from deterministic QR(Y)
* U = first r_v columns, stored as overlays_U.

9.3 DeltaW

* Z = U^T * W_O * H    // r_v x r_v

Store overlays_DeltaW = Z.

Runtime overlay path is fully determined by (H,U,Z).

10. FFN collapse to sparse linear

10.1 Inputs

Per layer l:

* W1[l] in R^{h x d_in}
* W2[l] in R^{d_out x h}
* b1[l] in R^{h}, b2[l] in R^{d_out}

10.2 Influence matrix

* S = |W2| * |W1|   // size d_out x d_in
* Use blocked GEMM, absolute values fused.

10.3 Top-L selection

For each input index j:

* I_j = indices of top-L entries in column j of S by magnitude.

* For each output i:

  e_ij = sum_{h in I_j} sign( W2[i,h] * W1[h,j] ) * max(0, |W2[i,h]| * |W1[h,j]|)

* Add e_ij into base weight for logical feature (l, j).

Residual contributions (h not in I_j) are candidates for delta dict.

10.4 Keying

Stable 64-bit key:

* key = ((u64)l << 32) | (u64)j

10.5 MPHF for linear

* Input: all keys used by base weights.
* Build MPHF as in tokenizer step, with its own salt and M.
* linear_mphf.bin:

  * stores M, bucket seeds, and metadata.
* linear_weights.bin:

  * index = h(key)
  * value = f32 base weight
* linear_keys.bin:

  * at index h(key): original key (for offline verification).

10.6 Cuckoo delta

* Residual (key, val) pairs inserted into bounded cuckoo:

  * fixed number of hash funcs d
  * fixed bucket size b
  * stash size S
  * max relocations L_cuckoo = 8
  * optional overflow ring Q = C/32

* Insertion order deterministic by (layer, j, i, h).

* Overflow conditions:

  * If constraints violated, record in manifest and stop inserting further residuals.
  * Runtime remains correct but with reduced approximation quality.

11. Positional encoding -> rational memory

11.1 RoPE

If RoPE detected:

* Derive per-head angle parameters.
* Compute average angle theta_bar.

Set:

* rho in {0.99, 0.995}
* a1 = 2 * rho * cos(theta_bar)
* a2 = -rho^2

Difference equation:

* y_t = a1 * y_{t-1} + a2 * y_{t-2} + u_t

Store {a1, a2, 1.0} in memory_coeff.bin.

11.2 ALiBi / learned abs

* Generate synthetic score response to shift.
* Fit limited-order ARMA/SOS with fixed seed:

  * p <= 2, q <= 1, L <= 6.
* If any pole radius >= 1:

  * multiply all feedback coeffs by 0.95, up to 3 times.
* If still unstable:

  * downgrade to simpler stable filter and record.

11.3 Delay buffer

* Choose T_phi, K as bounded constants.
* delaybuf_init is all zeros.
* Runtime uses DF-II in f64, cast to f32 single-site.

12. Bridge hubs and guards

12.1 Hubs

If ROUTER_GATE present:

* For each expert e:

  * m_e = L2 norm of gate weights.
* Sort experts by m_e descending; pick top-H as hubs.

If absent:

* Generate H pseudo-hubs via splitmix64; store mapping.

12.2 Bitsets

* H_bits = 64 * W; W in {2,3}.
* For each (token_id, context_id):

  For leg in [0..W-1]:

  * idx = mix64(token_id xor (context_id << 1) xor leg) >> (64 - log2(H_bits))
  * Set corresponding bit.

12.3 Quantization

Q8.8 format:

* Stored as int16:

  * real_value = q / 256.0
* For vector x:

  * choose row scale s so that:

    * p99(|x|) maps to <= 0.832767 * 32767 / 256
  * q_i = clamp( round(x_i * 256 / s), -32768, 32767 )

Store per-row s; eps_row_policy uses these scales.

12.4 Guards

* For top-K promoted pairs by fixed hash-based score:

  * Precompute margin m and competitor bounds.
* If any computed guard implies inconsistency (m <= 0, NaN):

  * Do not use promotion for that pair.

13. Numerics, threads, reductions

* All reductions in deterministic order.
* Sums in f64 where feasible.
* FMA and FTZ configuration stored in abi_flags.
* No approximate random libraries.
* All acceptance tests (section 16) must pass bit-exactly.

14. Stage DAG

Fixed, acyclic:

1. parse_tensors
2. tokenizer_build_or_wrap
3. prf_build
4. overlays_build
5. ffn_collapse
6. mphf_cuckoo
7. memory_fit
8. bridge_init
9. manifest_emit
10. check

Each stage:

* Writes its files once.
* Computes crc32c and sha256_low64.
* May only depend on prior stage outputs.

15. Acceptance tests (must pass)

Against fixed synthetic seeds:

* PRF vs softmax-like baseline:

  * Relative L2 error <= 1e-2 on 1k random (q,K,V).
* Linear collapse:

  * MAPE <= 0.5% on random sparse inputs (density <= 0.01).
* Memory:

  * Cosine similarity >= 0.97 vs reference positional behavior at window 32.
* Bridge:

  * Guard precheck pass-rate >= 0.9.
* Determinism:

  * Two complete runs produce identical:

    * all array payloads
    * all headers
    * sera_manifest.bin
    * diagnostic logs (excluding timestamps if any; recommend none).

16. Failure handling (strict)

If any check fails:

* Do NOT introduce nondeterminism, retraining, or heuristic loops.
* Apply only the following:

16.1 MPHF build failure

* Increase M by 5% (rounded up).
* Rebuild MPHF for that subsystem only.
* If still failing:

  * mark MPHF-based feature as disabled; fall back to direct table (if small) or abort conversion with explicit code.

16.2 Overlays orthogonality failure

* Rerun QR once with tighter threshold.
* If still failing:

  * omit overlays_* arrays; record "no_overlays".

16.3 Unstable poles

* Scale feedback coefficients by 0.95 up to 3 times.
* If still unstable:

  * select simpler stable filter or disable memory feature.

16.4 Guard inconsistency

* Disable promotions for affected entries.

16.5 CRC or hash mismatch

* Never change payload bytes.
* If header wrong:

  * recompute header (once) from existing payload.
* If payload wrong:

  * mark file invalid; disable dependent feature.

Conversion either:

* yields a consistent minimal Sera package, or
* fails with explicit error; no undefined partial state.

17. Minimal practical profile (20B-class)

For a 20B-class model (dense or MoE small):

* Choose:

  * r   = 512
  * r_v = 12
  * L_tok = 8
  * topL  = 12
  * L_cuckoo = 8
  * K = 6, W = 2
* Run:

  * `stk convert --in input --out out --r 512 --rv 12 --Ltok 8 --topL 12 --threads 16`
  * `stk check --out out`

Result:

* Total arrays: ~1–3 GiB depending on shapes.
* CPU-only.
* Fully deterministic.
* Directly consumable by Sera runtime using the manifest and array contracts above.



1. Add fp_contract section to manifest
   (Place under Manifest sections alongside tokenizer/prf/etc.)

fp_contract:
  fma_mode          // 0 = disabled, 1 = enabled
  denormals_mode    // 0 = preserve, 1 = flush_to_zero
  ext_precision     // 0 = none, 1 = double_double, 2 = long_double (if used)
  reductions_digest // 64-bit or 128-bit hash over reduction orders, kernels, and LUTs


Constraints:

The fp_contract section MUST be present.

fma_mode and denormals_mode MUST match the effective hardware/software configuration
used during STK conversion. If ext_precision != 0 is used anywhere, that usage
MUST be documented in reductions_digest and confined to a single well-defined
reduction site as specified in the FP contract.

Sera runtime MUST validate fp_contract against its own capabilities and reject
or sandbox generations whose fp_contract it cannot honor.


2. Define trust_gate absence semantics
   (Place in the Manifest description and/or in a new "Optional module semantics" subsection.)

Trust gate section (trust_gate) is OPTIONAL in STK outputs.

If the trust_gate stanza is absent in sera_manifest.bin:

  - The trust gate MUST be treated as disabled for this generation.
  - All trust_decision values are implicitly "Unknown".
  - No additional gating, caps, or penalties derived from the trust gate
    may be applied to attention, linear, bridge, CFR, or search modules.
  - Any fields in Diagnostics that relate to trust gate behavior MUST
    either be zeroed or marked as inactive.

This configuration is a valid Sera v2.3 model state.


3. Clarify optional module OFF rules (CFR, search, overlays, etc.)
   (Short unified rule; append near "Any missing optional array implies feature disabled".)

Optional module semantics:

For any module controlled by a dedicated manifest stanza and/or arrays:

  - If its stanza is missing, or all of its capacity/limit fields are zero,
    and no corresponding data arrays are present, the module is considered OFF.
  - OFF means:
      * No calls on that module's hot path.
      * No dynamic allocation or background activity for that module.
      * Outputs are replaced by fixed neutral elements (e.g. no overlays,
        no CFR contributions, no search steps).
  - This rule applies to: overlays, bridge O(0) fast path, search, CFR,
    trust_gate, and any future optional modules.

Sera runtimes MUST NOT assume undocumented behavior for missing sections.


4. Clarify module identification (no extra headers)
   (Place near Common array header / module header discussion.)

Module identification:

STK does not introduce an additional per-file ModuleHeader distinct from the
Common array header. Module identity is defined by:

  - The filename (arrays/*.bin), and
  - The corresponding stanza and field names in sera_manifest.bin.

Arrays and manifest entries MUST use the canonical Sera v2.3 names.
Runtimes MUST treat these names as the authoritative mapping between
binaries and logical modules.


5. Clarify salts and separation for trust gate vs bridge
   (Align with v2.3 security model; short addition to salts description.)

Salt domains:

The salts used for MPHF constructions and bridge/store keying MUST be
logically disjoint from any salts or keys used by a trust gate profile.

If a trust_gate stanza is present, its salts_digest MUST be computed over
a distinct key domain from mphf_salt_digest and key_salt_digest.

If trust_gate is absent, STK MUST NOT emit trust_gate salts in any other stanza.

6. Deterministic OFF behavior for bridge O(0)
   (Just to make the guard semantics line up tightly.)

If bridge_hubs.bin or bridge_qDin.bin or bridge_qDout.bin is absent, or if
the bridge stanza is missing, the external bridge MUST run in a fully OFF mode:

  - No dictionary O(0) lookups.
  - No two-hop scoring.
  - No modification of y_base by external references.
  - Diagnostics for O(0) hits and guard are set to zero or inactive.


